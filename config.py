GPT2_124M_Config = {
    "vocab_size": 50257,
    "ctx_length": 1024,
    "embed_dim": 768,
    # effectively n_blocks
    "n_layers": 12,
    "n_heads": 12,
    "drop_rate": 0.1
}
